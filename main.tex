\documentclass{article}

%install your packages here 
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsthm}
\usepackage{setspace}
\usepackage{cancel}
\usepackage{bbm}
\usepackage{pgfplots}
\usepackage{listings}
\usepackage{multicol}
\usepackage{diagbox}
\usepackage{ tipa }
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\usetikzlibrary{arrows, calc, patterns, shapes}
  \pgfplotsset{compat=1.15}
\renewcommand{\baselinestretch}{1.25}
\newcommand\sbullet[1][.5]{\mathbin{\vcenter{\hbox{\scalebox{#1}{$\bullet$}}}}}

%theorems
\theoremstyle{definition}
\newtheorem{theorem}{Theorem}

\theoremstyle{definition}
\newtheorem{definition}{Definition}

\newtheorem{example}{Example}[section]

%write short hand notes here 
%standard stats
\def\E{\mathbb{E}}
\def\l{\ell}
\def\xs{\{x_1, \hdots, x_n\}}
\def\Xs{\{X_1, \hdots, X_n\}}

%standard cal
\def\j{\mathcal{J}}
\def\sumn{\sum^n_{i=1}}
\def\inv{^{-1}}
\def\w{\omega}
\def\R{\mathbb{R}}
\def\fish{\mathcal{I}}

%symbols
\newcommand{\dotrel}[1]{\mathrel{\dot{#1}}}



\title{Math 806222 - Analysis of Extreme Values}
\author{Jean }
\date{Fall 2020}

\begin{document}
%makes the title and initial page
\maketitle
\tableofcontents{}
\pagebreak

\section{Introduction}
\subsection{Motivation}
This class has for focus the analysis of extreme values. This is not to be confused with extreme value theory. Theorems, lemmas, and concepts in this course will be defined and applied but not necessarily fleshed out or proved. These details can be found in the supplementary suggested readings. The tools from this class can be applied to finance, economics and financial engineering.
\subsection{Modeling}
\begin{definition}[Statistical Modeling] The use of sample data to make inferences of the probability structure of the population from which the data arose is referred to as \textbf{statistical modeling}.
\end{definition}
Given $\xs$ as independent (but not necessarily identically distributed) realisations/observations from a population of interest, in order to make any inference on these observations, we must first estimate the distribution. There are two methods for distribution estimation: \textbf{parametric modeling}, and \textbf{non-parametric modeling}. As we will see, the parametric approach is more suitable for extreme value analyses while the non-parametric method is only useful to capture some dependency issues.

\section{Parametric Modeling}
There are three steps to parametric modeling:
\begin{enumerate}
    \item Choosing a family of models within which the distribution of the data is assumed to lie
    \item Finding the family member from (1) that best corresponds to the data at hand
    \begin{enumerate}
        \item Parameter estimation
        \item Confidence interval for estimates
    \end{enumerate}
    \item Model diagnostics and evaluation
\end{enumerate}

\subsection{Choosing a Family}
Once we choose a family, we assume, for the rest of our parametric modeling, that the chose family was correct. It is important to note that once we have chosen, there is no way to correct for having chosen the wrong family. The choice of family is made based on:
\begin{itemize}
    \item \textbf{Physical Grounds:} what the process that sourced our data actually entails. (i.e. if we were observing coin flips we would use Binomial, if we were observing counts we would use Poisson).
    \item \textbf{Empirical Grounds:} what the exploratory analysis shows (i.e. if $\bar{x}\approx s$ then we might want to use an exponential family).
    \item \textbf{Limit Laws:} using an approximate model (i.e. Central Limit Theorem)
\end{itemize}

\subsection{Parameter Estimation}
Let $\xs$ be independent observations of random variables with a probability density function that is in a known familly of functions:
\[\mathcal{F} = \{f(x,\theta); \theta\in\Theta \} \]
with $\theta$ as either a scalar or a $d$-dimensional vector. Let $\theta_0$ be the true value of $\theta$ that generated our observed data. To estimate this unknown parameter, we can use any of the following:
\begin{itemize}
    \item Maximum likelihood estimation
    \item Method of moments
    \item Probability weighted methods
    \item Bayesian methods
    \item Robust methods of estimation
\end{itemize}

\subsubsection{Brief Review of Maximum Likelihood Estimation}
\begin{definition}[Likelihood Function] The probability of the observed data as a function of an unknown parameter $\theta$ is called the \textbf{likelihood function}. Assuming the observations are independent, the likelihood function is
\[\mathcal{L}(\theta)=\prod_{i=1}^n f_i(x_i; \theta)\]
with $f_i$ being the pdf/pmf of the i$^{th}$ observation. In practice, since the $\log$ function is monotonically increasing, maximizing the likelihood is equivalent to maximizing the log-likelihood. So we instead maximize 
\[\l(\theta)= \log(\mathcal{L}(\theta))= \sumn \log(f_i(x_i;\theta))\]

The maximum likelihood estimator $\hat{\theta}_0$ is defined by the value of $\theta$ that maximizes $\l(\theta)$. To get this, we must solve the equation below for $\theta$:
\[\frac{\partial}{\partial \theta} \l(\theta)=0\]
which can be done by hand or using the \texttt{optim} function from \texttt{R}.
\end{definition}

\subsection{Confidence Intervals}
Once we have estimated our parameter $\theta$, we need to build confidence intervals for the true parameter in order to evaluate the accuracy of our estimate.

\begin{definition}[Expected Information Matrix] The \textbf{expected information matrix}, also known as the \textbf{Fisher information matrix} measures the expected curvature of the log-likelihood and has information about the variability of estimated parameters. Assuming $\theta$ is $d$-dimensional, the EIM is represented by 
\[\fish_E(\theta)= \begin{bmatrix}e_{11}(\theta) &\hdots &\hdots & e_{1d}(\theta)\\
\vdots& \ddots & & \vdots\\
\vdots& &\ddots & \vdots\\
e_{d1}(\theta)& \hdots & \hdots& e_{dd}(\theta)\\
\end{bmatrix}\]
Where 
\[e_{ij}(\theta)=\E\bigg\{- \frac{\partial^2}{\partial \theta_i\partial\theta_j}\l(\theta) \bigg\}\]
\end{definition}


\begin{definition}[Observed Information Matrix]
This is an approximation of the expected information matrix. Since $\theta$ is rarely known, in practice, we use the \textbf{observed information matrix}:
\[\fish_O(\theta)= 
\begin{bmatrix}-\frac{\partial^2}{\partial \theta_1^2}\l(\theta)  &\hdots &\hdots & -\frac{\partial^2}{\partial \theta_1\partial\theta_d}\l(\theta) \\
\vdots& \ddots & & \vdots\\
\vdots& &\ddots &\vdots \\
-\frac{\partial^2}{\partial \theta_d\partial\theta_1}\l(\theta) & \hdots & \hdots& -\frac{\partial^2}{\partial \theta_d^2}\l(\theta) \\
\end{bmatrix}\]
This can be manually calculated or retrieved from the \texttt{optim} function in \texttt{R}.
\end{definition}

\begin{theorem}
Under suitable regularity conditions, for large $n$, 
\[\hat{\theta}_0 \dotrel{\sim} \textit{MVN}\Big(\theta_0, \fish_{E}(\theta_0)\inv \Big)\]
Where $\dotrel{\sim}$ means ``approximately distributed as". If $\theta$ is multidimensional, we can break this down. First, we denote $\fish_{E}(\theta_0)\inv$ as $\Psi_{i,j}$. Then, for all $\theta_i$ in $\theta_0=(\theta_1,\hdots, \theta_d)$, we have 
\[\hat\theta_i\dotrel{\sim} N(\theta_i, \Psi_{ii})\]
This can be used to build confidence intervals for $\theta_i$. Note that in practice, $\fish_O(\hat{\theta})$ is used instead of $\fish_E(\theta_0)$.

This theorem holds when we have many observations (large $n$). In many (most) extreme values problems, by the very nature of extreme value statistics, we simply do not have enough samples to apply Theorem 1. Additionally, for some extreme value problems, the regularity conditions that Theorem 1 assumes are not satisfied.
\end{theorem}
\begin{theorem}
Let $\phi=g(\theta)$ where $g$ is a scalar function. If $\hat{\theta}_0$ is the maximum likelihood estimator (MLE) for $\theta_0$, then, the MLE for $\phi$ is $\hat{\phi}_0=g(\hat{\theta}_0)$
\end{theorem}

\begin{theorem}As above, let $\phi=g(\theta)$. Furthermore, let $\hat{\theta}_0$ be the large sample MLE of the $d$-dimensional parameter $\theta_0$ with approximate variance-covariance matrix $V_{\theta}$. Then, it follows that

\[\hat{\phi}_0\dotrel{\sim} N(\phi_0, V_\phi)\]
where 
\[V_\phi= \nabla \phi^T V_\theta\nabla \phi\]
and
\[\nabla\phi=\bigg[ \frac{\partial \phi}{\partial\theta_1}, \hdots,\frac{\partial \phi}{\partial\theta_d} \bigg] \hspace{.3cm} \text{evaluated at }\hat{\theta}_0\]
computing an estimate of the variance of $\hat{\phi}_0$ using $V_{\theta}$ is known as the \textbf{delta method}
\end{theorem}
\subsubsection{Deviance}
Another method of creating confidence intervals is through the use of the \textbf{deviance function}:
\[D(\theta)= 2\{ \underbrace{\l(\hat{\theta}_0)}_{\text{largest likelihood}} - \underbrace{\l(\theta)}_{\text{likelihood at some other $\theta$}}\}\]
Once we have the deviance function, a natural criterion for a confidence region using a threshold $c$ is to define the region as
\[CR=\{\theta| D(\theta)\leq c\}\]

\begin{theorem}For large $n$, under suitable regularity conditions, 
\[D(\theta_0)\dotrel{\sim} \chi^2_d\]
From this theorem, it follows that a $(1-\alpha)100\%$ confidence interval for $\theta_0$ is given as 
\[C_\alpha= \{\theta| D(\theta)\leq \chi_{\alpha,d}^2\}\]
where is the upper $\alpha$-quantile of a $\chi^2$ distribution with $d$ degrees of freedom. This method of creating confidence intervals is usually more accurate then Theorem 1.
\end{theorem}
Since Theorem 4 often outperforms Theorem 1, it is of interest to see if we can apply a similar method to get confidence intervals for individual $\theta_i$. To do this, we will need one more tool.
\begin{definition}[Profile Likelihood]
Let $\theta_{-i}$ denote all the vector components of $\theta$ except $\theta_i$. Then, the \textbf{profile likelihood}(PLL) for $\theta_i$ is defined as 
\[\l_p(\theta_i)= \max_{\theta_{-i}}\l(\theta_i, \theta_{-i})\]
This means that for each value $\theta_i$, the PLL is the maximized log likelihood over all other ($d-1$) components of $\theta$.
\end{definition}

\begin{theorem}For large $n$, under suitable regularity conditions, we can recover the \textbf{profile deviance}:
\[D_p(\theta_i)= 2 \{ \l(\hat{\theta}_0) - \l_p(\theta_i)\}\dotrel{\sim} \chi^2_1\]
From this, it follows that a $(1-\alpha)100\%$ confidence interval for $\theta_i$ is
\[C_\alpha = \{\theta_i | D_p(\theta_i)\leq \chi^2_{\alpha,1}\}\]
where $\theta_i$ in $C_\alpha$ represents possible values of the $i^{th}$ component of $\theta$ rather than the true value of the $i^{th}$ component.
Now, let us examine the retaining criterion in the RHS of the equation above:
\begin{align*}
    &D_p(\theta_i)\leq \chi_{\alpha,1}^2\\
    &=2 \{ \l(\hat{\theta}_0) - \l_p(\theta_i)\} \leq \chi_{\alpha,1}^2\\
    &= \l(\hat{\theta}_0) - \l_p(\theta_i) \leq \frac{\chi_{\alpha,1}^2}{2}\\
    &= \l_p(\theta_i) \geq \l(\hat{\theta}_0) -\frac{\chi_{\alpha,1}^2}{2} \tag{*}
\end{align*}
In practice, we build the the PLL function $\l_p(\theta_i)$ and find the range of values $\theta_i$ such that (*) holds.
\end{theorem}

\begin{definition}[Deviance Statistic]
Theorem 5 can be used for model selection. Let $M_1$ be a model with parameter $\theta$, $M_0$ be a subset of $M_1$ where $k$ of the components of $\theta$ are constrained to 0, and let $\l_j(M_j)$ be the corresponding log-likelihood for model $j$. The \textbf{deviance statistic} is
\[D=2\{\l(M_1) - \l(M_0)\}\]
\end{definition}

\begin{theorem}Let
\begin{align*}
    \mathcal{H}_0: & M_0 \text{ is valid}\\
    \mathcal{H}_A: & M_1 \text{ is a better fit}
\end{align*}
We reject $\mathcal{H}_0$ in favor of $\mathcal{H}_A$ if 
\[D=2\{\l(M_1) - \l(M_0)\}>\chi^2_{\alpha,k}\]
\end{theorem}
\subsection{Model diagnostics}
Remember, nowhere in our parametric modeling have we accounted for choosing the wrong family. Here, we assess how well the model we assumed fits to the data we have. Ideally, we would use cross validation on one or more held out sets. However, since we are dealing with extreme value statistics, we will rarely have enough data to use this method. In practice, we instead evaluate the concordance between our model and the data it estimates.
\begin{definition}[Empirical Distribution Function]
Given an ordered sample of independent observations:
\[x_{(1)}\leq \hdots \leq x_{(n)} \]
from a population with \textbf{true} cumulative distribution function $F$, we define the \textbf{empirical distribution function} as

\[\Tilde{F}(x)=\frac{i}{n+1} \hspace{1cm} \text{for } x_{(i)}\leq x< x_{(i+1)}\]
\end{definition}
Let $\hat{F}$ be an estimate for $F$ from our model. Then, it follows that $\Tilde{F}$ and $\hat{F}$ should be in agreement. In fact, there are various goodness of fit procedures based on comparisons of $\Tilde{F}$ and $\hat{F}$.

\begin{definition}[P-P plot] a \textbf{probability probability plot} (pp plot) consists of the points 
\[ \Bigg\{ \bigg(\hat{F}(x_{(i)}), \frac{i}{n+1}\bigg)| i=1, \hdots, n \Bigg\}\]
note that this is essentially the same as plotting our estimate of $\hat{F}$ from the model against the empirical distribution function $\Tilde{F}$. The goal here is to check that the empirical distribution function is aligned with the model estimate for the distribution function while accounting for the probability scale.
\end{definition}

\begin{definition}[Q-Q plot] a \textbf{quantile quantile plot} (qq plot) consists of the points 
\[ \Bigg\{ \bigg(\hat{F}\inv (\frac{i}{n+1}), x_{(i)}\bigg)| i=1, \hdots, n \Bigg\}\]

This plot is more focused on the comparing the tail behavior of $\hat{F}$ and $\Tilde{F}$. In a qq plot, we plot the quantiles of our model estimate against the quantiles of our empirical distribution function and hope they lign up.
\end{definition}
When running model diagnostics, it is important to use both a pp plot and a qq plot as they give the same information but on different scales.

\section{Fundementals of Extreme Value Theory}
Usually, we define $\Xs$ as our random values of interest measured on a time scale(i.e. daily stock, weekly rainfall, ...). These may or may not be iid observations but for now, let $\Xs$ be a sequence of iid observations with distribution function $F$. Consider the random variable
\[M_n=\max\Xs\]
In this section, we will focus on maxima but it is important to note that the same calculations can be done on minima (or simply changing the sign of observed values and sticking with max calculations). If $n$ is the number of observations in a year, then $M_n$ is the \textbf{annual maximum}. Furthermore, we can calculate its distribution
\[F_{M_n}(z)=P(M_n\leq z)= \prod_{i=1}^nF_{X_i}(z)=[F(z)]^n\]
If $F$ is known, then finding the distribution function of $M_n$ is fairly straightforward. In practice however, $F$ is not known. To find the distribution of $M_n$, we could try to find an estimate $\hat{F}$ and use it to calculate $\hat{M}_n\sim [\hat{F}]^n$ but we can see that small mistakes in the estimation of $F$ will grow into significant errors in the estimation of the distribution of $\hat{M}_n$ as $n \rightarrow \infty$. Instead, we look for approximating families to model $F^n$.

Let $z_+ $ the the smallest value such that $F(z)=1$. Then, for all $z<z_+$, we have 
\[\lim_{n\rightarrow \infty}F(z)^n=0\]
This means that the distribution of $M^n$ \textbf{degenerates} to a point mass at $z_+$ as $n\rightarrow \infty$ . To avoid dealing with such distributions, we allow for re-normalizations of $M_n$:
\[\frac{M_n- b_n}{a_n} \hspace{1cm} a_n>0\]
Where the right choice of sequences $a_n$ and $b_n$ stabilize the location and scale of $M_n$ as $n$ increases.

\subsection{Approximating Distributions for Maxima}
\begin{theorem}
Let $\w(F)=\sup\{x:F(x)<1\}=+\infty$\footnote{The cdf $F$ has a horizontal asymptote at y=1}. Furthermore, let us assume $\exists$ a constant $\alpha>0$ such that $\forall x>0$
\[ \lim_{t\rightarrow \infty} \frac{1-F(tx)}{1-F(t)}=x^{-\alpha} \tag{$\Delta$}\]
Here, $(\Delta)$ tells us how much probability there is in the tail and that $X$ is a \textbf{regularly varying} random variable. If the above holds, then $\exists$ a sequence $a_n>0$ such that 
\[\lim_{n \rightarrow \infty} P\bigg( \frac{M_n}{a_n} <x \bigg)= \begin{cases}\exp (x^{-\alpha}) & x>0\\
0 & x\leq 0
\end{cases}\]
and the sequence can be chosen as 
\[ a_n=\inf \bigg\{ x:1-F(x)\leq \frac{1}{n} \bigg\}\]
When this is the case, we say that F is \textbf{the domain of attraction of Fréchet} and we write $F\in $MDA(Fréchet).
\end{theorem}

\begin{theorem}
Let $\w(F)$ be finite (i.e. if $F$ is uniform $\w(F)=1$). Furthermore. assume that the distribution function 
\[F^*(x)=F\bigg(\w(F)-\frac{1}{x}\bigg) \hspace{1cm} \forall x>0 \]
satisfies condition $(\Delta)$ from Theorem 7. Then, $\exists \{a_n\}, \{b_n\}$ such that 
\[\lim_{n\rightarrow \infty}P \bigg[ \frac{M_n-b_n}{a_n} < x\bigg]=\begin{cases}1 & x\geq 0\\
\exp(-x(-x)^\alpha)&x<0
\end{cases}\]
Where the normalizing constants can be chosen as 
\begin{align*}
    b_n&=\w(F)\\
    a_n&=\w(F)- \inf\{x:1-F(x)\leq \frac{1}{n}\}
\end{align*}
When this is the case, we say that F is \textbf{the domain of attraction of Weibull} and we write $F\in $MDA(Weibull).
\end{theorem}

\begin{theorem}
Assume that for some finite $a$
\[\int_a^{\w(F)} (1-F(y))dy < \inf\]
Then, for $x$ in the range $\inf\{x:F(x)>0\}<x<\w(F)$, we define 
\[R(t)= (1-F(t))\inv \int_t^{\w(t)} (1-F(y))dy\]
Finally, assume that $\forall x \in \mathbb{R}$
\[\lim_{t\rightarrow \w(F)} \frac{1-F(t+xR(t))}{1-F(t)}\underset{\footnotemark}{=}e^{-x}\]
Then $\exists$ sequences $\{a_n\}>0,\{b_n\}$ such that 
\[\lim_{n\rightarrow \infty}P \bigg[ \frac{M_n-b_n}{a_n} < x\bigg]=\exp(-\exp(-x)) \hspace{0.5 cm} \forall x\in \mathbb{R}\]
Where the normalizing constants can be chosen as 
\begin{align*}
    b_n&=\inf\{x:1-F(x)\leq \frac{1}{n}\}\\
    a_n&=R(b_n)
\end{align*}
When this is the case, we say that F is \textbf{the domain of attraction of Gumbell} and we write $F\in $MDA(Gumbell).
\footnotetext{this means $F$ has (light) exponential tails. This forces a restriction on the decay of the distribution}

\end{theorem}

Below are some notes on the last 3 theorems:
\begin{itemize}
    \item Theorems 7-9 exhaust all possibilities for the existence of the asymptotic distribution of maxima of iid rv (i.e. if F does not fall in any of the categories above then there are no normalizing constants that lead to a non-degenerate limit).
    \item The choice of constants $a_n,b_n$ is not unique. Changing these will yield a family with the same $\alpha$ parameter but (perhaps) different location and scale parameters
    \item In the past, we would choose one of the three proposed families to use to model $M_n$. Then, any inference made from this assumption would rely on the presupposition that we had made the correct choice of family. Now of course, there is a better solution.
\end{itemize}

\subsection{Generalized Extreme Value Family}
\begin{theorem}
If there exists sequences $\{a_n\},\{b_n\}$ such that 
\[\lim_{n\rightarrow\infty}P \bigg[\frac{M_n-b_n}{a_n}\leq z \bigg]=G(z)\tag{$\diamond$}\]
for a non-degenerate distribution function $G$, then $G$ is a member of the \textbf{generalized extreme value }(GEV) family and can be written as 
\[G(z)=\exp\bigg\{ - \bigg[1+\xi \bigg(\frac{z-\mu}{\sigma}\bigg)\bigg]^{-\frac{1}{\xi}}\bigg\}\]
defined on 
\[\{z:\bigg[1+\xi \bigg(\frac{z-\mu}{\sigma}\bigg)\bigg]^{-\frac{1}{\xi}}>0\}\]
Below are the parameter specifications of a GEV distribution.
\begin{itemize}
\item $\mu\in\R $ is a location parameter
\item $\sigma\in\R^+$ is a scale parameter
    \item $\xi\in \R$ is a shape parameter
\end{itemize}
\end{theorem}
\subsection{Properties of GEVs}
\subsubsection{Statistical properties}
Let $X\sim GEV(\mu, \sigma,\xi)$, then
\begin{align*}
    \E(X)&=\mu+\frac{\sigma}{\xi}(g_1-1)\\
    Var(X)&=\frac{\sigma^2}{\xi^2}(g_2-g_1)\\
    Mode(X)&=\mu+\frac{\sigma}{\xi}[(1+\xi)^{-\xi} -1]
\end{align*}
Where \[g_k=\Gamma(1-k\xi)\hspace{1cm} k\in\{1,2\}\]
and 
\[\Gamma(x)=\int_0^{\infty}t^{x-1}e^{-t}dt\]
\subsubsection{Analytic Properties}
Since a $GEV$ is defined on $1+\xi \bigg(\frac{z-\mu}{\sigma}\bigg)>0$, it follows that there is an upperbound on $x$ when $\xi<0$ and a lower bound when $\xi>0$
\[\begin{cases}
x < \frac{\mu-\sigma}{\xi}& \xi<0\\
x > \frac{\mu-\sigma}{\xi}& \xi>0
\end{cases}\]
Furthermore, assuming $(\diamond)$ holds for large enough values of $n$, we have 
\begin{align*}
    G(z)&\approx P \bigg[\frac{M_n-b_n}{a_n}\leq z \bigg]\\
    \implies P(M_n\leq z)& \approx G\bigg(\frac{z-b_n}{a_n}\bigg)\\
    &=G^*(z)
\end{align*}
Where $G^*$ is another member of the $GEV$ family.
\begin{definition}[Max-stability] A distribution is said to be \textbf{max-stable} if $\forall n=\{2,3,\hdots\}$, there are constraints $\alpha_n,\beta_n$ such that 
\[G^n(\alpha_nz+\beta_n)=G(z)\]
Where $G^n$ is the distribution of $M_n$. This definition shows that max-stable distributions are those where the sample maxima leads to identical distribution apart from a change of scale and location. 

\end{definition}
\begin{theorem}
A distribution is max-stable iff it is a GEV.
\end{theorem}
\noindent With this result, we can derive the following ``proof'' for Theorem 10. First, we know that for large enough $n$,
\[P\bigg[\frac{M_n-b_n}{a_n}\leq z \bigg]  \approx G(z)\]
Then, for any integer $k$, $nk$ is at least as large as $n$ so
\[P\bigg[\frac{M_{nk}-b_{nk}}{a_{nk}}\leq z \bigg]  \approx G(z) \tag{$\clubsuit$}\]
But since $M_nk$ is the maximum of $k$ variables having the same distribution as $M_n$, we have
\[P\bigg[\frac{M_{nk}-b_{nk}}{a_{nk}}\leq z \bigg] =\bigg( P\bigg[\frac{M_n-b_n}{a_n}\leq z \bigg]\bigg)^k \tag{$\spadesuit$}\]
So we have
\begin{align*}
    (\clubsuit)&\implies P(M_{nk}\leq z)\approx G(\frac{z-b_{nk}}{a_{nk}})\\
    (\spadesuit)&\implies P(M_{n}\leq z)\approx G^k(\frac{z-b_n}{a_n})
\end{align*}
Which shows that $G$ is max-stable and therefore, a $GEV$.


\section{Modeling Univariate Extremes}
\subsection{Block Maxima}
Given independent observations of $\{x_1,x_2,\hdots\}$, of data block (or separate) into sequences of observations each having length $n$ for large $n$. This generates the sequence of maxima $\{M_{n,1},\hdots,M_{n,m}\}$ to which we can fit a $GEV$. See now we split our data into maximal data and use the distribution of max-like data for interpretation. Note: the choice of block size is critical. It gives rise to the standard bias-variance trade-off we often come across in statistics. Having blocks that are too small may mean that the approximation by the limit model is likely to be poor whereas having large blocks generate few block maxima, thus leading to a large estimation variance. For this section, let us consider the maximum likelihood estimator for GEVs.

Since the support of a GEV depends on the parameters, we see that it is possible to run into difficulties when making the regularity assumptions that so many of our MLE theorems depend on. For this reason, we analyse 3 cases:
\begin{enumerate}
    \item $\xi>-0.5$: This yields a \textbf{regula} MLE and we can make the standard normality assumptions
    \item $-1<\xi<-0.5$: We can usually optain an MLE but these do not have the standard asymptotic properties
    \item $\xi<-1$: MLE are likely to be unobtainable.
\end{enumerate}

Let $\{z_1,\hdots,z_m\}$ denote the block maxima assumed to be independent random variables following a GEV distribution; the MLE can be found through likelihood function:
\[\l(\mu,\sigma,\xi)=-m\log(\sigma)-(1+\frac{1}{\xi})\sum_{i=1}^m \log[1+\xi(\frac{z_i-\mu}{\sigma})]- \sum_{i=1}^m[1+\xi(\frac{z_i-\mu}{\sigma})]^{-1/\xi}\]
provided of course that \[1+\xi(\frac{z_i-\mu}{\sigma})>0\hspace{1cm}  i=1,2,\hdots,m\]
Otherwise, the likelihood is 0 and he log-likelihood is $-\infty$ for that observation. It is important to note that there is no analytical solution for the MLE of a GEV. Numerical approximations must be used 
on a re-parameterized log-likelihood to obtain the best estimates.

\subsubsection{Quantiles}
When analyzing extremal data, the quantities of interest are usually the extreme upper quantiles of the (annual) maximum distribution. To do this, we invert $G(z_p)=1-p$ to find
\[z_p=\begin{cases} \mu=\frac{\sigma}{\xi}[1-\{-\log(1-p)\}^{-\xi}] & \xi\neq 0\\
\mu-\sigma\log\{-\log(1-p)\}&\xi= 0
\end{cases} \tag{**}\]
We refer to the \textbf{return level} $z_p$ associated with the \textbf{return period} $\frac{1}{p}$. For example, if we were observing annual rain data, $z_p$ would be the amount of rain  expected to be exceeded on average once every  $\frac{1}{p}$ years. Or $z_p$ is expected to be exceeded by the annual maximum once ever  $\frac{1}{p}$ years.

We can let $y_p=-\log(1-p)$ and plot $z_p$ from $(**)$ against $y_p$ on a log scale. When we do this we observe 3 distinct behaviors:
\begin{enumerate}
    \item $\xi=0$: the plot is linear
    \item $\xi>0$: the plot is convex with no finite bound
    \item $\xi<0$: the plot is concave with an asymptotic limit as $p\rightarrow 0$
\end{enumerate}
In practice, we want to estimate $z_p$. To do so using normality, we substitute the MLE into $(**)$ and use the delta method to obtain a 95\% confidence interval. This yields mixed results as the normal approximation for the MLE may be poor (especially $\hat{\xi},\hat{z}_p $)
\subsubsection{Profile Likelihood}
Instead of the delta method, we can use the profile likelihood to create our confidence interval for $Z_p$ using Theorem 4. We first, reparameterize the likelihood function using
\[\mu=z_p+\frac{\sigma}{\xi}[1-\{-\log(1-p)\}^{-\xi}]\]
Then, we consider the likelihood function as a function of $z_p$:
\[l(z_p)= \max_{\xi, \sigma}\l(z_p,\xi, \sigma)\]


\end{document}